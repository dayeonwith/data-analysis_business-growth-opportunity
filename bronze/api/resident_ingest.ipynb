{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b12d9d2-f029-4a7e-8901-23e86e6f74f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# install library\n",
    "# %pip install requests\n",
    "# %pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc58e24e-e0e3-4539-98b6-b3c4a3e5a60e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 1. api information\n",
    "api_endpoint = '/15100023/v1/uddi:9b422ba6-4f79-4424-80f4-addeb8c89306'\n",
    "base_url = 'https://api.odcloud.kr/api'\n",
    "url = f'{base_url}{api_endpoint}'\n",
    "\n",
    "# set initial variables\n",
    "all_data = []\n",
    "page = 1\n",
    "perPage = 500\n",
    "\n",
    "# load environment variables from .env\n",
    "load_dotenv() \n",
    "## call API_KEY saved in .env\n",
    "api_key = os.getenv(\"API_KEY\") \n",
    "print(api_key)\n",
    "\n",
    "# 2. get data\n",
    "while True:\n",
    "    params = {\n",
    "        'page' : page,\n",
    "        'perPage' : perPage,\n",
    "        'serviceKey' : api_key\n",
    "    }\n",
    "\n",
    "    print(f'processing page: {page}')\n",
    "\n",
    "    # send api request\n",
    "    response = requests.get(url, params)\n",
    "    # check request status\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # using .get() in case there is no data returned. In that case, new_data will be []\n",
    "        new_data = data.get('data', []) \n",
    "        # new_data is empty, escape the loop\n",
    "        if len(new_data) == 0:\n",
    "            break\n",
    "        # add the data to the all_data\n",
    "        all_data.append(new_data)\n",
    "        # move to the next page\n",
    "        page += 1\n",
    "    # error on request -> escape the look\n",
    "    else:\n",
    "        print(f'error code: {response.status_code}')\n",
    "        print(f'error message: {response.text}')\n",
    "        #side note: if this was a ELT pipeline, unless the error is 4xx, I would have implemented retry mechanism with incremental gaps between the tries before failing the pipeline, maybe three times.\n",
    "        break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ce4a3a3-c9c9-4acf-bbca-d2f35a037c66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# read data from api\n",
    "def read_data(base_url, endpoint, api_key):\n",
    "    # 1. api information\n",
    "    api_endpoint = endpoint\n",
    "    url = f'{base_url}{api_endpoint}'\n",
    "\n",
    "    # set initial variables\n",
    "    all_data = []\n",
    "    page = 1\n",
    "    perPage = 500\n",
    "    api_key = api_key    \n",
    "\n",
    "    # 2. get data\n",
    "    while True:\n",
    "        params = {\n",
    "            'page' : page,\n",
    "            'perPage' : perPage,\n",
    "            'serviceKey' : api_key\n",
    "        }\n",
    "        # send api request\n",
    "        response = requests.get(url, params)\n",
    "        # check request status\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            # using .get() in case there is no data returned. In that case, new_data will be []\n",
    "            new_data = data.get('data', []) \n",
    "            # new_data is empty, escape the loop\n",
    "            if len(new_data) == 0:\n",
    "                break\n",
    "            # add the data to the all_data\n",
    "            all_data.append(new_data)\n",
    "            # move to the next page\n",
    "            page += 1\n",
    "        # error on request -> escape the look\n",
    "        else:\n",
    "            print(f'error code: {response.status_code}')\n",
    "            print(f'error message: {response.text}')\n",
    "            #side note: if this was a ELT pipeline, unless the error is 4xx, I would have implemented retry mechanism with incremental gaps between the tries before failing the pipeline, maybe three times.\n",
    "            break\n",
    "    return all_data\n",
    "\n",
    "# load environment variables from .env\n",
    "load_dotenv() \n",
    "## call API_KEY saved in .env\n",
    "api_key = os.getenv(\"API_KEY\") \n",
    "base_url = 'https://api.odcloud.kr/api'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15b4e2db-0714-49a3-9a2c-ee566c84ebfd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# get a list of endpoint from a textfile\n",
    "with open('resident_endpoints.txt', 'r') as f:\n",
    "    endpoints_to_read = [line.strip() for line in f]\n",
    "\n",
    "total_results = []\n",
    "\n",
    "# loop through each endpoint \n",
    "for ep in endpoints_to_read:\n",
    "    result_data = read_data(base_url, ep, api_key)\n",
    "    total_results.append(result_data)\n",
    "\n",
    "# 최종 결과 확인\n",
    "print(\"--- All processes finished ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02ff2ab4-02b6-4e48-b430-add46539693c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "total_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64459326-4ebf-4e91-b6da-ef55f7bc6d57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "resident_ingest",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
