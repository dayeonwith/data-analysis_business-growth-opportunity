{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "565db79a-a077-42e2-894e-272c800c3468",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#%pip install langdetect\n",
    "#%pip install kss\n",
    "#%pip install nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bdeba3b-3bb0-4170-84fb-159c239f5346",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, current_timestamp\n",
    "from langdetect import detect\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import kss\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "788d7061-9550-4f7e-894c-bf45a33cbe50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Download the 'punkt' tokenizer model (only needs to be done once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a00f43c-841d-4196-9542-ff6082b02425",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9b3100d-861b-45ae-9cd5-1ab48ba9d6d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"silver_reddit_load\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee0e8d9f-33eb-4fa6-b784-70cfb6891848",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# get data from bronze table\n",
    "bronze_df = spark.table(\"workspace.growth_poc.bronze_reddit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06a34c75-01e3-46a2-b7c3-be3a76737b07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert Spark DataFrame to Pandas DataFrame \n",
    "# (need to run row-level language detection with langdetect)\n",
    "pd_df = bronze_df.toPandas().rename(columns = {\"created_datetime\": \"created_datetime_unix\"})\n",
    "pd_df['created_datetime'] = pd.to_datetime(pd_df['created_datetime_unix'].astype(float), unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6d13b1f-ad90-4ed7-b52d-ff901f526099",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def detect_language(text):\n",
    "    if not text or str(text).strip() == \"\":\n",
    "        return \"n/a\"\n",
    "    try:\n",
    "        wrttien_language = detect(text)\n",
    "        return wrttien_language\n",
    "    # if text is not detectable, put n/a\n",
    "    except:\n",
    "        return \"n/a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b1d5719-99ab-4179-88f5-78d8859d5625",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# detect written language\n",
    "pd_df['language'] = pd_df['content'].apply(detect_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06227bfb-0e73-418f-a275-0b34270527f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "new_rows = []\n",
    "# loop through each row\n",
    "for index, row in pd_df.iterrows():\n",
    "    # for korean, use kss \n",
    "    if(row['language']) == 'kr':\n",
    "        sentences = kss.split_sentences(row['content'])\n",
    "    # everything else, use nltk for sentence separation\n",
    "    else:\n",
    "        sentences = sent_tokenize(row['content'])       \n",
    "    for sentence in sentences:\n",
    "            new_rows.append({\n",
    "                'url': row['url'],\n",
    "                'content': row['content'],  \n",
    "                'sentence': sentence,       \n",
    "                'created_datetime_unix': row['created_datetime_unix'],\n",
    "                'score': row['score'],\n",
    "                'category': row['category'],\n",
    "                'language': row['language'],\n",
    "                'created_datetime': row['created_datetime']\n",
    "            })\n",
    "# create dataframe\n",
    "sentence_df = pd.DataFrame(new_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bb4fb0b-7890-44e0-b8de-a5a372c8cc2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# add timestamp\n",
    "spark_df = spark.createDataFrame(sentence_df).withColumn(\"timestamp\", current_timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b627274-b479-4d9f-aa26-af638006cae0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark_df.write\\\n",
    "        .mode(\"overwrite\")\\\n",
    "        .format(\"delta\")\\\n",
    "        .option(\"mergeSchema\", \"true\")\\\n",
    "        .saveAsTable(\"workspace.growth_poc.silver_reddit_reviews\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7432506752166599,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "reddit_load",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
