{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26c2d3ce-71cf-4598-b951-2bc34f6369db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_json, explode_outer, when, lit, sum\n",
    "from pyspark.sql.types import ArrayType, StructType, StructField, StringType, IntegerType\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08e76c5d-6277-4e61-8e42-5bf3d46a035b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Get data from bronze\n",
    "spark = SparkSession.builder.appName(\"silver_resident_shortterm\").getOrCreate()\n",
    "bronze_df = spark.table(\"workspace.growth_poc.bronze_residents_shortterm\")\n",
    "\n",
    "# 2. Cleaning up\n",
    "cleaned_df = clean_data(bronze_df)\n",
    "\n",
    "# 3. Apply mapping\n",
    "mapped_df = map_nationality(cleaned_df)\n",
    "\n",
    "mapped_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"workspace.growth_poc.silver_residents_shortterm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c898c8fa-8f0c-4300-9986-22b7643f53e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_data(bronze_df):\n",
    "    # since the data is currently JSON string, \n",
    "    # I need to convert it back to JSON object using from_json\n",
    "    resident_schema = StructType([\n",
    "        StructField(\"국적지역\", StringType(), False),\n",
    "        StructField(\"년\", IntegerType(), False),\n",
    "        StructField(\"단기체류외국인 수\", IntegerType(), False)  \n",
    "    ])\n",
    "    \n",
    "    # using from_json, the column `data` (JSON string) is converted into ArrayType(StructType)\n",
    "    # Each element is now a struct mapping the original JSON object's key-value pairs.\n",
    "    resident_df = bronze_df.withColumn(\"data_parsed\", from_json(col(\"data\"), ArrayType(resident_schema)))\n",
    "\n",
    "    # flatten the array\n",
    "    exploded_df = resident_df.select(explode_outer(col(\"data_parsed\")))\n",
    "\n",
    "    # convert each item in struct as a column\n",
    "    processed_df = exploded_df.select(\n",
    "        col(\"col.국적지역\").alias(\"Nationality\"),\n",
    "        col(\"col.년\").alias(\"Year\"),\n",
    "        col(\"col.`단기체류외국인 수`\").alias(\"Amount\")\n",
    "    )\n",
    "\n",
    "    # replace vague nationality with None\n",
    "    exclude_list = [\n",
    "        \"기타\", \"국제연합\", \"미등록국가\", \"교황청\", \"무국적\",\n",
    "        \"영국속국민\",\"영국속령지시민\",\"영국외지민\",\"영국외지시민\",\"영국해외영토시민\"\n",
    "    ]\n",
    "\n",
    "    # clean up nationalities\n",
    "    replacement_dict = {\n",
    "        # 러시아 관련\n",
    "        \"러시아(연방)\": \"러시아\",\n",
    "        \"러시아연방\": \"러시아\",\n",
    "        \"한국계러시아인\": \"러시아\",\n",
    "        \n",
    "        # 남수단\n",
    "        \"남수단공화국\": \"남수단\",\n",
    "        \n",
    "        # 그루지야 / 조지아\n",
    "        \"그루지야\": \"조지아\",\n",
    "        \n",
    "        # 프랑스\n",
    "        \"불령가이아나\": \"프랑스\",\n",
    "        \"프랑스령 가이아나\": \"프랑스\",\n",
    "\n",
    "        # 아르메니아\n",
    "        \"아르메\": \"아르메니아\",\n",
    "        \n",
    "        # 세르비아몬테네그로 → 세르비아  \n",
    "        \"세르비아몬테네그로\": \"세르비아\",\n",
    "        \n",
    "        # 러시아/중국/홍콩 관련\n",
    "        \"홍콩거주난민\": \"홍콩\",\n",
    "        \"한국계중국인\": \"중국\",\n",
    "        \n",
    "        # 예시: 긴 명칭 간소화\n",
    "        \"남아프리카공화국\": \"남아프리카\",\n",
    "        \"도미니카공화국\": \"도미니카\",\n",
    "        \"도미니카연방\": \"도미니카\",\n",
    "        \"티모르민주공화국\": \"티모르\",\n",
    "        \n",
    "        # 기타 소형 섬 / 특수 영토 간소화\n",
    "        \"미국인근섬\": \"미국\",\n",
    "        \"마르티니크\": \"프랑스\",\n",
    "        \"마카오\": \"중국\",\n",
    "        \"세인트빈센트그레나딘\": \"세인트빈센트\",  \n",
    "        \"세인트크리스토퍼네비스\": \"세인트키츠네비스\",\n",
    "        \"영령인도양섬\": \"영국\"\n",
    "        \n",
    "    }\n",
    "\n",
    "    cleaned_df = processed_df.select(\n",
    "        when(col(\"Nationality\").isin(exclude_list), lit(None)).otherwise(col(\"Nationality\")).alias(\"Nationality\")\n",
    "        , \"Year\"\n",
    "        , \"Amount\"\n",
    "    ).replace(replacement_dict, subset = ['Nationality'])\n",
    "\n",
    "    #cleaned_df = cleaned_df.replace(replacement_dict, subset = ['Nationality'])\n",
    "    cleaned_df = cleaned_df.groupBy([\"Nationality\", \"Year\"]).agg(\n",
    "        sum(\"Amount\").alias(\"Amount\")\n",
    "    )\n",
    "    return cleaned_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6dd7ef43-bd8b-4c32-8f54-b48607d5594e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def map_nationality(cleaned_df):\n",
    "    # read csv file containing map country code\n",
    "    df = pd.read_csv(\"/Workspace/Repos/o3oynyn@gmail.com/data-analysis_business-growth-opportunity/silver/Nationality_mapping.csv\", index_col=None)\n",
    "\n",
    "    # convert pandas df to spark df\n",
    "    mapping_df = spark.createDataFrame(df)\n",
    "\n",
    "    mapped_df = cleaned_df.join(mapping_df, \\\n",
    "                                cleaned_df['Nationality'] == mapping_df['Korean_Nationality'], \\\n",
    "                                how = \"left\")\\\n",
    "                            .select(\n",
    "                                [col(c) for c in cleaned_df.columns] \n",
    "                                + [col(c) for c in mapping_df.columns if c != \"Korean_Nationality\"]\n",
    "                            )\n",
    "    return mapped_df\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6693409348114582,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_resident_shortterm_load",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
